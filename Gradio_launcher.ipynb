{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/abs121/home/anaconda3/envs/vid-sam-4/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://d4bb15bc2a16eb70df.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d4bb15bc2a16eb70df.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get meta information of input video\n",
      "No module named 'spatial_correlation_sampler'\n",
      "Failed to import PyTorch Correlation, For better efficiency, please install it.\n",
      "No module named 'spatial_correlation_sampler'\n",
      "Failed to import PyTorch Correlation, For better efficiency, please install it.\n",
      "No module named 'spatial_correlation_sampler'\n",
      "Failed to import PyTorch Correlation, For better efficiency, please install it.\n",
      "SegTracker has been initialized\n",
      "Everything\n",
      "Ready to add new object!\n",
      "Click\n",
      "Ready to add new object!\n",
      "Click\n",
      "Ready to add new object!\n",
      "Click\n",
      "No module named 'spatial_correlation_sampler'\n",
      "Failed to import PyTorch Correlation, For better efficiency, please install it.\n",
      "No module named 'spatial_correlation_sampler'\n",
      "Failed to import PyTorch Correlation, For better efficiency, please install it.\n",
      "No module named 'spatial_correlation_sampler'\n",
      "Failed to import PyTorch Correlation, For better efficiency, please install it.\n",
      "SegTracker has been initialized\n",
      "No module named 'spatial_correlation_sampler'\n",
      "Failed to import PyTorch Correlation, For better efficiency, please install it.\n",
      "No module named 'spatial_correlation_sampler'\n",
      "Failed to import PyTorch Correlation, For better efficiency, please install it.\n",
      "No module named 'spatial_correlation_sampler'\n",
      "Failed to import PyTorch Correlation, For better efficiency, please install it.\n",
      "SegTracker has been initialized\n",
      "Ready to add new object!\n",
      "Click\n",
      "Ready to add new object!\n",
      "Click\n"
     ]
    }
   ],
   "source": [
    "%run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL.ImageOps import colorize, scale\n",
    "import gradio as gr\n",
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "import pdb\n",
    "import json\n",
    "from matplotlib.pyplot import step\n",
    "\n",
    "from model_args import segtracker_args,sam_args,aot_args\n",
    "from SegTracker import SegTracker\n",
    "from tool.transfer_tools import draw_outline, draw_points\n",
    "# sys.path.append('.') \n",
    "# sys.path.append('..')\n",
    "\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.morphology.binary import binary_dilation\n",
    "import argparse\n",
    "import torch\n",
    "import time, math\n",
    "from seg_track_anything import aot_model2ckpt, tracking_objects_in_video, draw_mask\n",
    "import gc\n",
    "import numpy as np\n",
    "import json\n",
    "from tool.transfer_tools import mask2bbox\n",
    "\n",
    "from moviepy.editor import VideoFileClip \n",
    "def clean():\n",
    "    return None, None, None, None, None, None, [[], []]\n",
    "\n",
    "\n",
    "def get_click_prompt(click_stack, point):\n",
    "\n",
    "    click_stack[0].append(point[\"coord\"])\n",
    "    click_stack[1].append(point[\"mode\"]\n",
    "    )\n",
    "    \n",
    "    prompt = {\n",
    "        \"points_coord\":click_stack[0],\n",
    "        \"points_mode\":click_stack[1],\n",
    "        \"multimask\":\"True\",\n",
    "    }\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def get_meta_from_video(input_video):\n",
    "    if input_video is None:\n",
    "        return None, None, None, \"\"\n",
    "\n",
    "    print(\"get meta information of input video\")\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "    \n",
    "    _, first_frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    first_frame = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return first_frame, first_frame, first_frame, \"\"\n",
    "\n",
    "def get_meta_from_img_seq(input_img_seq):\n",
    "    if input_img_seq is None:\n",
    "        return None, None, None, \"\"\n",
    "\n",
    "    print(\"get meta information of img seq\")\n",
    "    # Create dir\n",
    "    file_name = input_img_seq.name.split('/')[-1].split('.')[0]\n",
    "    file_path = f'./assets/{file_name}'\n",
    "    if os.path.isdir(file_path):\n",
    "        os.system(f'rm -r {file_path}')\n",
    "    os.makedirs(file_path)\n",
    "    # Unzip file\n",
    "    os.system(f'unzip {input_img_seq.name} -d ./assets ')\n",
    "    \n",
    "    imgs_path = sorted([os.path.join(file_path, img_name) for img_name in os.listdir(file_path)])\n",
    "    first_frame = imgs_path[0]\n",
    "    first_frame = cv2.imread(first_frame)\n",
    "    first_frame = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return first_frame, first_frame, first_frame, \"\"\n",
    "\n",
    "def SegTracker_add_first_frame(Seg_Tracker, origin_frame, predicted_mask):\n",
    "    with torch.cuda.amp.autocast():\n",
    "        # Reset the first frame's mask\n",
    "        frame_idx = 0\n",
    "        Seg_Tracker.restart_tracker()\n",
    "        Seg_Tracker.add_reference(origin_frame, predicted_mask, frame_idx)\n",
    "        Seg_Tracker.first_frame_mask = predicted_mask\n",
    "\n",
    "    return Seg_Tracker\n",
    "\n",
    "def init_SegTracker(aot_model, long_term_mem, max_len_long_term, sam_gap, max_obj_num, points_per_side, origin_frame):\n",
    "    \n",
    "    if origin_frame is None:\n",
    "        return None, origin_frame, [[], []], \"\"\n",
    "\n",
    "    # reset aot args\n",
    "    aot_args[\"model\"] = aot_model\n",
    "    aot_args[\"model_path\"] = aot_model2ckpt[aot_model]\n",
    "    aot_args[\"long_term_mem_gap\"] = long_term_mem\n",
    "    aot_args[\"max_len_long_term\"] = max_len_long_term\n",
    "    # reset sam args\n",
    "    segtracker_args[\"sam_gap\"] = sam_gap\n",
    "    segtracker_args[\"max_obj_num\"] = max_obj_num\n",
    "    sam_args[\"generator_args\"][\"points_per_side\"] = points_per_side\n",
    "    \n",
    "    Seg_Tracker = SegTracker(segtracker_args, sam_args, aot_args)\n",
    "    Seg_Tracker.restart_tracker()\n",
    "\n",
    "    return Seg_Tracker, origin_frame, [[], []], \"\"\n",
    "\n",
    "def init_SegTracker_Stroke(aot_model, long_term_mem, max_len_long_term, sam_gap, max_obj_num, points_per_side, origin_frame):\n",
    "    \n",
    "    if origin_frame is None:\n",
    "        return None, origin_frame, [[], []], origin_frame\n",
    "\n",
    "    # reset aot args\n",
    "    aot_args[\"model\"] = aot_model\n",
    "    aot_args[\"model_path\"] = aot_model2ckpt[aot_model]\n",
    "    aot_args[\"long_term_mem_gap\"] = long_term_mem\n",
    "    aot_args[\"max_len_long_term\"] = max_len_long_term\n",
    "\n",
    "    # reset sam args\n",
    "    segtracker_args[\"sam_gap\"] = sam_gap\n",
    "    segtracker_args[\"max_obj_num\"] = max_obj_num\n",
    "    sam_args[\"generator_args\"][\"points_per_side\"] = points_per_side\n",
    "    \n",
    "    Seg_Tracker = SegTracker(segtracker_args, sam_args, aot_args)\n",
    "    Seg_Tracker.restart_tracker()\n",
    "    return Seg_Tracker, origin_frame, [[], []], origin_frame\n",
    "\n",
    "def undo_click_stack_and_refine_seg(Seg_Tracker, origin_frame, click_stack, aot_model, long_term_mem, max_len_long_term, sam_gap, max_obj_num, points_per_side):\n",
    "    \n",
    "    if Seg_Tracker is None:\n",
    "        return Seg_Tracker, origin_frame, [[], []]\n",
    "\n",
    "    print(\"Undo!\")\n",
    "    if len(click_stack[0]) > 0:\n",
    "        click_stack[0] = click_stack[0][: -1]\n",
    "        click_stack[1] = click_stack[1][: -1]\n",
    "    \n",
    "    if len(click_stack[0]) > 0:\n",
    "        prompt = {\n",
    "            \"points_coord\":click_stack[0],\n",
    "            \"points_mode\":click_stack[1],\n",
    "            \"multimask\":\"True\",\n",
    "        }\n",
    "\n",
    "        masked_frame = seg_acc_click(Seg_Tracker, prompt, origin_frame)\n",
    "        return Seg_Tracker, masked_frame, click_stack\n",
    "    else:\n",
    "        return Seg_Tracker, origin_frame, [[], []]\n",
    "\n",
    "def roll_back_undo_click_stack_and_refine_seg(Seg_Tracker, origin_frame, click_stack, aot_model, long_term_mem, max_len_long_term, sam_gap, max_obj_num, points_per_side,input_video, input_img_seq, frame_num, refine_idx):\n",
    "    \n",
    "    if Seg_Tracker is None:\n",
    "        return Seg_Tracker, origin_frame, [[], []]\n",
    "\n",
    "    print(\"Undo!\")\n",
    "    if len(click_stack[0]) > 0:\n",
    "        click_stack[0] = click_stack[0][: -1]\n",
    "        click_stack[1] = click_stack[1][: -1]\n",
    "    \n",
    "    if len(click_stack[0]) > 0:\n",
    "        prompt = {\n",
    "            \"points_coord\":click_stack[0],\n",
    "            \"points_mode\":click_stack[1],\n",
    "            \"multimask\":\"True\",\n",
    "        }\n",
    "\n",
    "        chosen_frame_show, curr_mask, ori_frame = res_by_num(input_video, input_img_seq, frame_num)\n",
    "        Seg_Tracker.curr_idx = refine_idx\n",
    "        predicted_mask, masked_frame = Seg_Tracker.seg_acc_click( \n",
    "                                                        origin_frame=origin_frame, \n",
    "                                                        coords=np.array(prompt[\"points_coord\"]),\n",
    "                                                        modes=np.array(prompt[\"points_mode\"]),\n",
    "                                                        multimask=prompt[\"multimask\"],\n",
    "                                                        )\n",
    "        curr_mask[curr_mask == refine_idx]  = 0\n",
    "        curr_mask[predicted_mask != 0]  = refine_idx\n",
    "        predicted_mask=curr_mask\n",
    "        Seg_Tracker = SegTracker_add_first_frame(Seg_Tracker, origin_frame, predicted_mask)\n",
    "        return Seg_Tracker, masked_frame, click_stack\n",
    "    else:\n",
    "        return Seg_Tracker, origin_frame, [[], []]\n",
    "\n",
    "\n",
    "def seg_acc_click(Seg_Tracker, prompt, origin_frame):\n",
    "    # seg acc to click\n",
    "    predicted_mask, masked_frame = Seg_Tracker.seg_acc_click( \n",
    "                                                      origin_frame=origin_frame, \n",
    "                                                      coords=np.array(prompt[\"points_coord\"]),\n",
    "                                                      modes=np.array(prompt[\"points_mode\"]),\n",
    "                                                      multimask=prompt[\"multimask\"],\n",
    "                                                    )\n",
    "\n",
    "    Seg_Tracker = SegTracker_add_first_frame(Seg_Tracker, origin_frame, predicted_mask)\n",
    "\n",
    "    return masked_frame\n",
    "\n",
    "\n",
    "def sam_click(Seg_Tracker, origin_frame, point_mode, click_stack, aot_model, long_term_mem, max_len_long_term, sam_gap, max_obj_num, points_per_side, evt:gr.SelectData):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        origin_frame: nd.array\n",
    "        click_stack: [[coordinate], [point_mode]]\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Click\")\n",
    "\n",
    "    if point_mode == \"Positive\":\n",
    "        point = {\"coord\": [evt.index[0], evt.index[1]], \"mode\": 1}\n",
    "    else:\n",
    "        # TODO：add everything positive points\n",
    "        point = {\"coord\": [evt.index[0], evt.index[1]], \"mode\": 0}\n",
    "\n",
    "    if Seg_Tracker is None:\n",
    "        Seg_Tracker, _, _, _ = init_SegTracker(aot_model, long_term_mem, max_len_long_term, sam_gap, max_obj_num, points_per_side, origin_frame)\n",
    "\n",
    "    # get click prompts for sam to predict mask\n",
    "    click_prompt = get_click_prompt(click_stack, point)\n",
    "\n",
    "    # Refine acc to prompt\n",
    "    masked_frame = seg_acc_click(Seg_Tracker, click_prompt, origin_frame)\n",
    "\n",
    "    return Seg_Tracker, masked_frame, click_stack\n",
    "\n",
    "\n",
    "def roll_back_sam_click(Seg_Tracker, origin_frame, point_mode, click_stack, aot_model, long_term_mem, max_len_long_term, sam_gap, max_obj_num, points_per_side, input_video, input_img_seq, frame_num, refine_idx, evt:gr.SelectData):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        origin_frame: nd.array\n",
    "        click_stack: [[coordinate], [point_mode]]\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Click\")\n",
    "\n",
    "    if point_mode == \"Positive\":\n",
    "        point = {\"coord\": [evt.index[0], evt.index[1]], \"mode\": 1}\n",
    "    else:\n",
    "        # TODO：add everything positive points\n",
    "        point = {\"coord\": [evt.index[0], evt.index[1]], \"mode\": 0}\n",
    "\n",
    "    if Seg_Tracker is None:\n",
    "        Seg_Tracker, _, _, _ = init_SegTracker(aot_model, long_term_mem, max_len_long_term, sam_gap, max_obj_num, points_per_side, origin_frame)\n",
    "\n",
    "    # get click prompts for sam to predict mask\n",
    "    prompt = get_click_prompt(click_stack, point)\n",
    "\n",
    "    chosen_frame_show, curr_mask, ori_frame = res_by_num(input_video, input_img_seq, frame_num)\n",
    "\n",
    "    Seg_Tracker.curr_idx = refine_idx\n",
    "\n",
    "    predicted_mask, masked_frame = Seg_Tracker.seg_acc_click( \n",
    "                                                      origin_frame=origin_frame, \n",
    "                                                      coords=np.array(prompt[\"points_coord\"]),\n",
    "                                                      modes=np.array(prompt[\"points_mode\"]),\n",
    "                                                      multimask=prompt[\"multimask\"],\n",
    "                                                    )\n",
    "    curr_mask[curr_mask == refine_idx]  = 0\n",
    "    curr_mask[predicted_mask != 0]  = refine_idx\n",
    "    predicted_mask=curr_mask\n",
    "\n",
    "\n",
    "    Seg_Tracker = SegTracker_add_first_frame(Seg_Tracker, origin_frame, predicted_mask)\n",
    "\n",
    "    return Seg_Tracker, masked_frame, click_stack\n",
    "\n",
    "def sam_stroke(Seg_Tracker, origin_frame, drawing_board, aot_model, long_term_mem, max_len_long_term, sam_gap, max_obj_num, points_per_side):\n",
    "\n",
    "    if Seg_Tracker is None:\n",
    "        Seg_Tracker, _ , _, _ = init_SegTracker(aot_model, long_term_mem, max_len_long_term, sam_gap, max_obj_num, points_per_side, origin_frame)\n",
    "    \n",
    "    print(\"Stroke\")\n",
    "    mask = drawing_board[\"mask\"]\n",
    "    bbox = mask2bbox(mask[:, :, 0])  # bbox: [[x0, y0], [x1, y1]]\n",
    "    predicted_mask, masked_frame = Seg_Tracker.seg_acc_bbox(origin_frame, bbox)\n",
    "\n",
    "    Seg_Tracker = SegTracker_add_first_frame(Seg_Tracker, origin_frame, predicted_mask)\n",
    "\n",
    "    return Seg_Tracker, masked_frame, origin_frame\n",
    "\n",
    "def segment_everything(Seg_Tracker, aot_model, long_term_mem, max_len_long_term, origin_frame, sam_gap, max_obj_num, points_per_side):\n",
    "    \n",
    "    if Seg_Tracker is None:\n",
    "        Seg_Tracker, _ , _, _ = init_SegTracker(aot_model, long_term_mem, max_len_long_term, sam_gap, max_obj_num, points_per_side, origin_frame)\n",
    "\n",
    "    print(\"Everything\")\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        pred_mask = Seg_Tracker.seg(origin_frame)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        Seg_Tracker.add_reference(origin_frame, pred_mask, frame_idx)\n",
    "        Seg_Tracker.first_frame_mask = pred_mask\n",
    "\n",
    "    masked_frame = draw_mask(origin_frame.copy(), pred_mask)\n",
    "\n",
    "    return Seg_Tracker, masked_frame\n",
    "\n",
    "def add_new_object(Seg_Tracker):\n",
    "\n",
    "    prev_mask = Seg_Tracker.first_frame_mask\n",
    "    Seg_Tracker.update_origin_merged_mask(prev_mask)    \n",
    "    Seg_Tracker.curr_idx += 1\n",
    "\n",
    "    print(\"Ready to add new object!\")\n",
    "\n",
    "    return Seg_Tracker, [[], []]\n",
    "\n",
    "def tracking_objects(Seg_Tracker, input_video, input_img_seq, fps, frame_num=0):\n",
    "    print(\"Start tracking !\")\n",
    "    # pdb.set_trace()\n",
    "    # output_video, output_mask=tracking_objects_in_video(Seg_Tracker, input_video, input_img_seq, fps)\n",
    "    # pdb.set_trace()\n",
    "    return tracking_objects_in_video(Seg_Tracker, input_video, input_img_seq, fps, frame_num)\n",
    "\n",
    "\n",
    "def res_by_num(input_video, input_img_seq, frame_num):\n",
    "    if input_video is not None:\n",
    "        video_name = os.path.basename(input_video).split('.')[0]\n",
    "\n",
    "        cap = cv2.VideoCapture(input_video)\n",
    "        for i in range(0,frame_num+1):\n",
    "            _, ori_frame = cap.read()  \n",
    "        cap.release()\n",
    "        ori_frame = cv2.cvtColor(ori_frame, cv2.COLOR_BGR2RGB)\n",
    "    elif input_img_seq is not None:\n",
    "        file_name = input_img_seq.name.split('/')[-1].split('.')[0]\n",
    "        file_path = f'./assets/{file_name}'\n",
    "        video_name = file_name\n",
    "\n",
    "        imgs_path = sorted([os.path.join(file_path, img_name) for img_name in os.listdir(file_path)])\n",
    "        ori_frame = imgs_path[frame_num]\n",
    "        ori_frame = cv2.imread(ori_frame)\n",
    "        ori_frame = cv2.cvtColor(ori_frame, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "    tracking_result_dir = f'{os.path.join(os.path.abspath(\"\"), \"tracking_results\", f\"{video_name}\")}'\n",
    "    output_masked_frame_dir = f'{tracking_result_dir}/{video_name}_masked_frames'\n",
    "    output_masked_frame_path = sorted([os.path.join(output_masked_frame_dir, img_name) for img_name in os.listdir(output_masked_frame_dir)])\n",
    "\n",
    "    output_mask_dir = f'{tracking_result_dir}/{video_name}_masks'\n",
    "    output_mask_path = sorted([os.path.join(output_mask_dir, img_name) for img_name in os.listdir(output_mask_dir)])\n",
    "\n",
    "\n",
    "    if len(output_masked_frame_path) == 0:\n",
    "        return None, None, None\n",
    "    else:\n",
    "        if frame_num >= len(output_masked_frame_path):\n",
    "            print(\"num out of frames range\")\n",
    "            return None, None, None\n",
    "        else:\n",
    "            print(\"choose\", frame_num, \"to refine\")\n",
    "            chosen_frame_show = output_masked_frame_path[frame_num]\n",
    "            chosen_frame_show = cv2.imread(chosen_frame_show)\n",
    "            chosen_frame_show = cv2.cvtColor(chosen_frame_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            chosen_mask = output_mask_path[frame_num]\n",
    "            chosen_mask = cv2.imread(chosen_mask)\n",
    "\n",
    "            chosen_mask = Image.open(output_mask_path[frame_num]).convert('P')\n",
    "            chosen_mask = np.array(chosen_mask)\n",
    "\n",
    "            return chosen_frame_show, chosen_mask, ori_frame\n",
    "\n",
    "def show_res_by_slider(input_video, input_img_seq, frame_per):\n",
    "    if input_video is not None:\n",
    "        video_name = os.path.basename(input_video).split('.')[0]\n",
    "    elif input_img_seq is not None:\n",
    "        file_name = input_img_seq.name.split('/')[-1].split('.')[0]\n",
    "        file_path = f'./assets/{file_name}'\n",
    "        video_name = file_name\n",
    "    else:\n",
    "        print(\"Not find output res\")\n",
    "        return None, None\n",
    "\n",
    "    tracking_result_dir = f'{os.path.join(os.path.abspath(\"\"), \"tracking_results\", f\"{video_name}\")}'\n",
    "    output_masked_frame_dir = f'{tracking_result_dir}/{video_name}_masked_frames'\n",
    "    output_masked_frame_path = sorted([os.path.join(output_masked_frame_dir, img_name) for img_name in os.listdir(output_masked_frame_dir)])\n",
    "    total_frames_num = len(output_masked_frame_path)\n",
    "    if total_frames_num == 0:\n",
    "        print(\"Not find output res\")\n",
    "        return None, None\n",
    "    else:\n",
    "        frame_num = math.floor(total_frames_num * frame_per / 100)\n",
    "        if frame_per == 100:\n",
    "            frame_num = frame_num -1\n",
    "        chosen_frame_show, _, _ = res_by_num(input_video, input_img_seq, frame_num)\n",
    "        return chosen_frame_show, frame_num\n",
    "\n",
    "def choose_obj_to_refine(input_video, input_img_seq, Seg_Tracker, frame_num, evt:gr.SelectData):\n",
    "    chosen_frame_show, curr_mask, _ = res_by_num(input_video, input_img_seq, frame_num)\n",
    "    # curr_mask=Seg_Tracker.first_frame_mask\n",
    "    \n",
    "    if curr_mask is not None and chosen_frame_show is not None:\n",
    "        idx = curr_mask[evt.index[1],evt.index[0]]\n",
    "        curr_idx_mask = np.where(curr_mask == idx, 1, 0).astype(np.uint8)\n",
    "        chosen_frame_show = draw_points(points=np.array([[evt.index[0],evt.index[1]]]), modes=np.array([[1]]), frame=chosen_frame_show)\n",
    "        chosen_frame_show = draw_outline(mask=curr_idx_mask, frame=chosen_frame_show)\n",
    "        print(idx)\n",
    "    \n",
    "    return chosen_frame_show, idx\n",
    "\n",
    "def show_chosen_idx_to_refine(aot_model, long_term_mem, max_len_long_term, sam_gap, max_obj_num, points_per_side, input_video, input_img_seq, Seg_Tracker, frame_num, idx):\n",
    "    chosen_frame_show, curr_mask, ori_frame = res_by_num(input_video, input_img_seq, frame_num)\n",
    "    if Seg_Tracker is None:\n",
    "        print(\"reset aot args, new SegTracker\")\n",
    "        Seg_Tracker, _ , _, _ = init_SegTracker(aot_model, long_term_mem, max_len_long_term, sam_gap, max_obj_num, points_per_side, ori_frame)\n",
    "    # # reset aot args\n",
    "    # aot_args[\"model\"] = aot_model\n",
    "    # aot_args[\"model_path\"] = aot_model2ckpt[aot_model]\n",
    "    # aot_args[\"long_term_mem_gap\"] = long_term_mem\n",
    "    # aot_args[\"max_len_long_term\"] = max_len_long_term\n",
    "    # # reset sam args\n",
    "    # segtracker_args[\"sam_gap\"] = sam_gap\n",
    "    # segtracker_args[\"max_obj_num\"] = max_obj_num\n",
    "    # sam_args[\"generator_args\"][\"points_per_side\"] = points_per_side\n",
    "    \n",
    "    # Seg_Tracker = SegTracker(segtracker_args, sam_args, aot_args)\n",
    "    Seg_Tracker.restart_tracker()\n",
    "    Seg_Tracker.curr_idx = 1\n",
    "    Seg_Tracker.object_idx = 1\n",
    "    Seg_Tracker.origin_merged_mask = None\n",
    "    Seg_Tracker.first_frame_mask = None\n",
    "    Seg_Tracker.reference_objs_list=[]\n",
    "    Seg_Tracker.everything_points = []\n",
    "    Seg_Tracker.everything_labels = []\n",
    "    Seg_Tracker.sam.have_embedded = False\n",
    "    Seg_Tracker.sam.interactive_predictor.features = None\n",
    "    return ori_frame, Seg_Tracker, ori_frame, [[], []], \"\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def seg_track_app():\n",
    "\n",
    "    ##########################################################\n",
    "    ######################  Front-end ########################\n",
    "    ##########################################################\n",
    "    app = gr.Blocks()\n",
    "\n",
    "    with app:\n",
    "        gr.Markdown(\n",
    "            '''\n",
    "            <div style=\"text-align:center;\">\n",
    "                <span style=\"font-size:3em; font-weight:bold;\">Segment and Track Anything(SAM-Track)</span>\n",
    "            </div>\n",
    "            '''\n",
    "        )\n",
    "\n",
    "        click_stack = gr.State([[],[]]) # Storage clicks status\n",
    "        origin_frame = gr.State(None)\n",
    "        Seg_Tracker = gr.State(None)\n",
    "\n",
    "        current_frame_num = gr.State(None)\n",
    "        refine_idx = gr.State(None)\n",
    "        frame_num = gr.State(None)\n",
    "\n",
    "        aot_model = gr.State(None)\n",
    "        sam_gap = gr.State(None)\n",
    "        points_per_side = gr.State(None)\n",
    "        max_obj_num = gr.State(None)\n",
    "\n",
    "        with gr.Row():\n",
    "            # video input\n",
    "            with gr.Column(scale=0.5):\n",
    "\n",
    "                tab_video_input = gr.Tab(label=\"Video type input\")\n",
    "                with tab_video_input:\n",
    "                    input_video = gr.Video(label='Input video', height=550)\n",
    "                \n",
    "                tab_img_seq_input = gr.Tab(label=\"Image-Seq type input\")\n",
    "                with tab_img_seq_input:\n",
    "                    with gr.Row():\n",
    "                        input_img_seq = gr.File(label='Input Image-Seq', height=550)\n",
    "                        with gr.Column(scale=0.25):\n",
    "                            extract_button = gr.Button(value=\"extract\")\n",
    "                            fps = gr.Slider(label='fps', minimum=5, maximum=50, value=8, step=1)\n",
    "\n",
    "                input_first_frame = gr.Image(label='Segment result of first frame',interactive=True, height=550)\n",
    "\n",
    "\n",
    "                tab_everything = gr.Tab(label=\"Everything\")\n",
    "                with tab_everything:\n",
    "                    with gr.Row():\n",
    "                        seg_every_first_frame = gr.Button(value=\"Segment everything for first frame\", interactive=True)\n",
    "                        point_mode = gr.Radio(\n",
    "                            choices=[\"Positive\"],\n",
    "                            value=\"Positive\",\n",
    "                            label=\"Point Prompt\",\n",
    "                            interactive=True)\n",
    "\n",
    "                        every_undo_but = gr.Button(\n",
    "                                    value=\"Undo\",\n",
    "                                    interactive=True\n",
    "                                    )\n",
    "\n",
    "                            # every_reset_but = gr.Button(\n",
    "                            #             value=\"Reset\",\n",
    "                            #             interactive=True\n",
    "                            #                     )\n",
    "\n",
    "                tab_click = gr.Tab(label=\"Click\")\n",
    "                with tab_click:\n",
    "                    with gr.Row():\n",
    "                        point_mode = gr.Radio(\n",
    "                                    choices=[\"Positive\",  \"Negative\"],\n",
    "                                    value=\"Positive\",\n",
    "                                    label=\"Point Prompt\",\n",
    "                                    interactive=True)\n",
    "\n",
    "                        # args for modify and tracking \n",
    "                        click_undo_but = gr.Button(\n",
    "                                    value=\"Undo\",\n",
    "                                    interactive=True\n",
    "                                    )\n",
    "                            # click_reset_but = gr.Button(\n",
    "                            #             value=\"Reset\",\n",
    "                            #             interactive=True\n",
    "                            #                     )\n",
    "\n",
    "                tab_stroke = gr.Tab(label=\"Stroke\")\n",
    "                with tab_stroke:\n",
    "                    drawing_board = gr.ImageEditor(label='Drawing Board', brush=gr.Brush(default_size=10), interactive=True)\n",
    "                    with gr.Row():\n",
    "                        seg_acc_stroke = gr.Button(value=\"Segment\", interactive=True)\n",
    "                        # stroke_reset_but = gr.Button(\n",
    "                        #                 value=\"Reset\",\n",
    "                        #                 interactive=True\n",
    "                        #                         )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=0.5): \n",
    "                        with gr.Tab(label=\"SegTracker Args\"):\n",
    "                            # args for tracking in video do segment-everthing\n",
    "                            points_per_side = gr.Slider(\n",
    "                                label = \"points_per_side\",\n",
    "                                minimum= 1,\n",
    "                                step = 1,\n",
    "                                maximum=100,\n",
    "                                value=16,\n",
    "                                interactive=True\n",
    "                            )\n",
    "\n",
    "                            sam_gap = gr.Slider(\n",
    "                                label='sam_gap',\n",
    "                                minimum = 1,\n",
    "                                step=1,\n",
    "                                maximum = 9999,\n",
    "                                value=100,\n",
    "                                interactive=True,\n",
    "                            )\n",
    "\n",
    "                            max_obj_num = gr.Slider(\n",
    "                                label='max_obj_num',\n",
    "                                minimum = 50,\n",
    "                                step=1,\n",
    "                                maximum = 300,\n",
    "                                value=255,\n",
    "                                interactive=True\n",
    "                            )\n",
    "                            with gr.Accordion(\"aot advanced options\", open=False):\n",
    "                                aot_model = gr.Dropdown(\n",
    "                                    label=\"aot_model\",\n",
    "                                    choices = [\n",
    "                                        \"deaotb\",\n",
    "                                        \"deaotl\",\n",
    "                                        \"r50_deaotl\"\n",
    "                                    ],\n",
    "                                    value = \"r50_deaotl\",\n",
    "                                    interactive=True,\n",
    "                                )\n",
    "                                long_term_mem = gr.Slider(label=\"long term memory gap\", minimum=1, maximum=9999, value=9999, step=1)\n",
    "                                max_len_long_term = gr.Slider(label=\"max len of long term memory\", minimum=1, maximum=9999, value=9999, step=1)\n",
    "\n",
    "\n",
    "                    \n",
    "                    with gr.Column():\n",
    "                        new_object_button = gr.Button(\n",
    "                            value=\"Add new object\", \n",
    "                            interactive=True\n",
    "                        )\n",
    "                        reset_button = gr.Button(\n",
    "                            value=\"Reset\",\n",
    "                            interactive=True,\n",
    "                        )\n",
    "                        track_for_video = gr.Button(\n",
    "                            value=\"Start Tracking\",\n",
    "                                interactive=True,\n",
    "                                )\n",
    "\n",
    "            with gr.Column(scale=0.5):\n",
    "                # output_video = gr.Video(label='Output video').style(height=550)\n",
    "                output_video = gr.File(label=\"Predicted video\")\n",
    "                output_mask = gr.File(label=\"Predicted masks\")\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=1):\n",
    "                        with gr.Accordion(\"roll back options\", open=False):\n",
    "                        # tab_show_res = gr.Tab(label=\"Segment result of all frames\")\n",
    "                        # with tab_show_res:\n",
    "                            output_res = gr.Image(label='Segment result of all frames', height=550)\n",
    "                            frame_per = gr.Slider(\n",
    "                                label = \"Percentage of Frames Viewed\",\n",
    "                                minimum= 0.0,\n",
    "                                maximum= 100.0,\n",
    "                                step=0.01,\n",
    "                                value=0.0,\n",
    "                            )\n",
    "                            frame_per.release(show_res_by_slider, inputs=[input_video, input_img_seq, frame_per], outputs=[output_res, frame_num])\n",
    "                            roll_back_button = gr.Button(value=\"Choose this mask to refine\")\n",
    "                            refine_res = gr.Image(label='Refine masks', height=550)\n",
    "\n",
    "                            tab_roll_back_click = gr.Tab(label=\"Click\")\n",
    "                            with tab_roll_back_click:\n",
    "                                with gr.Row():\n",
    "                                    roll_back_point_mode = gr.Radio(\n",
    "                                                choices=[\"Positive\",  \"Negative\"],\n",
    "                                                value=\"Positive\",\n",
    "                                                label=\"Point Prompt\",\n",
    "                                                interactive=True)\n",
    "\n",
    "                                    # args for modify and tracking \n",
    "                                    roll_back_click_undo_but = gr.Button(\n",
    "                                                value=\"Undo\",\n",
    "                                                interactive=True\n",
    "                                                )\n",
    "                                    roll_back_track_for_video = gr.Button(\n",
    "                                    value=\"Start tracking to refine\",\n",
    "                                        interactive=True,\n",
    "                                        )\n",
    "\n",
    "    ##########################################################\n",
    "    ######################  back-end #########################\n",
    "    ##########################################################\n",
    "\n",
    "        # listen to the input_video to get the first frame of video\n",
    "        input_video.change(\n",
    "            fn=get_meta_from_video,\n",
    "            inputs=[\n",
    "                input_video\n",
    "            ],\n",
    "            outputs=[\n",
    "                input_first_frame, origin_frame, drawing_board\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # listen to the input_img_seq to get the first frame of video\n",
    "        input_img_seq.change(\n",
    "            fn=get_meta_from_img_seq,\n",
    "            inputs=[\n",
    "                input_img_seq\n",
    "            ],\n",
    "            outputs=[\n",
    "                input_first_frame, origin_frame, drawing_board\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        #-------------- Input compont -------------\n",
    "        tab_video_input.select(\n",
    "            fn = clean,\n",
    "            inputs=[],\n",
    "            outputs=[\n",
    "                input_video,\n",
    "                input_img_seq,\n",
    "                Seg_Tracker,\n",
    "                input_first_frame,\n",
    "                origin_frame,\n",
    "                drawing_board,\n",
    "                click_stack,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        tab_img_seq_input.select(\n",
    "            fn = clean,\n",
    "            inputs=[],\n",
    "            outputs=[\n",
    "                input_video,\n",
    "                input_img_seq,\n",
    "                Seg_Tracker,\n",
    "                input_first_frame,\n",
    "                origin_frame,\n",
    "                drawing_board,\n",
    "                click_stack,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "        extract_button.click(\n",
    "            fn=get_meta_from_img_seq,\n",
    "            inputs=[\n",
    "                input_img_seq\n",
    "            ],\n",
    "            outputs=[\n",
    "                input_first_frame, origin_frame, drawing_board\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "        # ------------------- Interactive component -----------------\n",
    "\n",
    "        # listen to the tab to init SegTracker\n",
    "        tab_everything.select(\n",
    "            fn=init_SegTracker,\n",
    "            inputs=[\n",
    "                aot_model,\n",
    "                long_term_mem,\n",
    "                max_len_long_term, \n",
    "                sam_gap,\n",
    "                max_obj_num,\n",
    "                points_per_side,\n",
    "                origin_frame\n",
    "            ],\n",
    "            outputs=[\n",
    "                Seg_Tracker, input_first_frame, click_stack\n",
    "            ],\n",
    "            queue=False,\n",
    "            \n",
    "        )\n",
    "        \n",
    "        tab_click.select(\n",
    "            fn=init_SegTracker,\n",
    "            inputs=[\n",
    "                aot_model,\n",
    "                long_term_mem,\n",
    "                max_len_long_term,\n",
    "                sam_gap,\n",
    "                max_obj_num,\n",
    "                points_per_side,\n",
    "                origin_frame\n",
    "            ],\n",
    "            outputs=[\n",
    "                Seg_Tracker, input_first_frame, click_stack\n",
    "            ],\n",
    "            queue=False,\n",
    "        )\n",
    "\n",
    "        tab_stroke.select(\n",
    "            fn=init_SegTracker_Stroke,\n",
    "            inputs=[\n",
    "                aot_model,\n",
    "                long_term_mem,\n",
    "                max_len_long_term,\n",
    "                sam_gap,\n",
    "                max_obj_num,\n",
    "                points_per_side,\n",
    "                origin_frame,\n",
    "            ],\n",
    "            outputs=[\n",
    "                Seg_Tracker, input_first_frame, click_stack, drawing_board\n",
    "            ],\n",
    "            queue=False,\n",
    "        )\n",
    "\n",
    "        # Use SAM to segment everything for the first frame of video\n",
    "        seg_every_first_frame.click(\n",
    "            fn=segment_everything,\n",
    "            inputs=[\n",
    "                Seg_Tracker,\n",
    "                aot_model,\n",
    "                long_term_mem,\n",
    "                max_len_long_term,\n",
    "                origin_frame,\n",
    "                sam_gap,\n",
    "                max_obj_num,\n",
    "                points_per_side,\n",
    "\n",
    "            ],\n",
    "            outputs=[\n",
    "                Seg_Tracker,\n",
    "                input_first_frame,\n",
    "            ],\n",
    "            )\n",
    "        \n",
    "        # Interactively modify the mask acc click\n",
    "        input_first_frame.select(\n",
    "            fn=sam_click,\n",
    "            inputs=[\n",
    "                Seg_Tracker, origin_frame, point_mode, click_stack,\n",
    "                aot_model,\n",
    "                long_term_mem,\n",
    "                max_len_long_term,\n",
    "                sam_gap,\n",
    "                max_obj_num,\n",
    "                points_per_side,\n",
    "            ],\n",
    "            outputs=[\n",
    "                Seg_Tracker, input_first_frame, click_stack\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Interactively segment acc stroke\n",
    "        seg_acc_stroke.click(\n",
    "            fn=sam_stroke,\n",
    "            inputs=[\n",
    "                Seg_Tracker, origin_frame, drawing_board,\n",
    "                aot_model,\n",
    "                long_term_mem,\n",
    "                max_len_long_term,\n",
    "                sam_gap,\n",
    "                max_obj_num,\n",
    "                points_per_side,\n",
    "            ],\n",
    "            outputs=[\n",
    "                Seg_Tracker, input_first_frame, drawing_board\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "        # Add new object\n",
    "        new_object_button.click(\n",
    "            fn=add_new_object,\n",
    "            inputs=\n",
    "            [\n",
    "                Seg_Tracker\n",
    "            ],\n",
    "            outputs=\n",
    "            [\n",
    "                Seg_Tracker, click_stack\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Track object in video\n",
    "        track_for_video.click(\n",
    "            fn=tracking_objects,\n",
    "            inputs=[\n",
    "                Seg_Tracker,\n",
    "                input_video,\n",
    "                input_img_seq,\n",
    "                fps,\n",
    "            ],\n",
    "            outputs=[\n",
    "                output_video, output_mask\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "        # ----------------- Refine Mask ---------------------------\n",
    "\n",
    "        output_res.select(\n",
    "            fn = choose_obj_to_refine,\n",
    "            inputs=[\n",
    "                input_video, input_img_seq, Seg_Tracker, frame_num\n",
    "            ],\n",
    "            outputs=[output_res, refine_idx]\n",
    "        )\n",
    "        \n",
    "\n",
    "        roll_back_button.click(\n",
    "            fn=show_chosen_idx_to_refine,\n",
    "            inputs=[\n",
    "                aot_model,\n",
    "                long_term_mem,\n",
    "                max_len_long_term, \n",
    "                sam_gap,\n",
    "                max_obj_num,\n",
    "                points_per_side,\n",
    "                input_video, input_img_seq, Seg_Tracker, frame_num, refine_idx\n",
    "            ],\n",
    "            outputs=[\n",
    "                refine_res, Seg_Tracker, origin_frame, click_stack\n",
    "            ],\n",
    "            queue=False,\n",
    "            show_progress=False\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        roll_back_click_undo_but.click(\n",
    "            fn = roll_back_undo_click_stack_and_refine_seg,\n",
    "            inputs=[\n",
    "                Seg_Tracker, origin_frame, click_stack,\n",
    "                aot_model,\n",
    "                long_term_mem,\n",
    "                max_len_long_term,\n",
    "                sam_gap,\n",
    "                max_obj_num,\n",
    "                points_per_side,\n",
    "                input_video, input_img_seq, frame_num, refine_idx\n",
    "            ],\n",
    "            outputs=[\n",
    "               Seg_Tracker, refine_res, click_stack\n",
    "            ]\n",
    "        ) \n",
    "\n",
    "        refine_res.select(\n",
    "            fn=roll_back_sam_click,\n",
    "            inputs=[\n",
    "                Seg_Tracker, origin_frame, roll_back_point_mode, click_stack,\n",
    "                aot_model,\n",
    "                long_term_mem,\n",
    "                max_len_long_term,\n",
    "                sam_gap,\n",
    "                max_obj_num,\n",
    "                points_per_side,\n",
    "                input_video, input_img_seq, frame_num, refine_idx\n",
    "            ],\n",
    "            outputs=[\n",
    "                Seg_Tracker, refine_res, click_stack\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "        # Track object in video\n",
    "        roll_back_track_for_video.click(\n",
    "            fn=tracking_objects,\n",
    "            inputs=[\n",
    "                Seg_Tracker,\n",
    "                input_video,\n",
    "                input_img_seq,\n",
    "                fps, frame_num\n",
    "            ],\n",
    "            outputs=[\n",
    "                output_video, output_mask\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "        # ----------------- Reset and Undo ---------------------------\n",
    "\n",
    "        # Rest \n",
    "        reset_button.click(\n",
    "            fn=init_SegTracker,\n",
    "            inputs=[\n",
    "                aot_model,\n",
    "                long_term_mem,\n",
    "                max_len_long_term,\n",
    "                sam_gap,\n",
    "                max_obj_num,\n",
    "                points_per_side,\n",
    "                origin_frame\n",
    "            ],\n",
    "            outputs=[\n",
    "                Seg_Tracker, input_first_frame, click_stack\n",
    "            ],\n",
    "            queue=False,\n",
    "            show_progress=False\n",
    "        ) \n",
    "\n",
    "\n",
    "\n",
    "        # every_reset_but.click(\n",
    "        #     fn=init_SegTracker,\n",
    "        #     inputs=[\n",
    "        #         aot_model,\n",
    "        #         sam_gap,\n",
    "        #         max_obj_num,\n",
    "        #         points_per_side,\n",
    "        #         origin_frame\n",
    "        #     ],\n",
    "        #     outputs=[\n",
    "        #         Seg_Tracker, input_first_frame, click_stack, grounding_caption\n",
    "        #     ],\n",
    "        #     queue=False,\n",
    "        #     show_progress=False\n",
    "        # ) \n",
    "\n",
    "        # click_reset_but.click(\n",
    "        #     fn=init_SegTracker,\n",
    "        #     inputs=[\n",
    "        #         aot_model,\n",
    "        #         sam_gap,\n",
    "        #         max_obj_num,\n",
    "        #         points_per_side,\n",
    "        #         origin_frame\n",
    "        #     ],\n",
    "        #     outputs=[\n",
    "        #         Seg_Tracker, input_first_frame, click_stack, grounding_caption\n",
    "        #     ],\n",
    "        #     queue=False,\n",
    "        #     show_progress=False\n",
    "        # ) \n",
    "\n",
    "        # stroke_reset_but.click(\n",
    "        #     fn=init_SegTracker_Stroke,\n",
    "        #     inputs=[\n",
    "        #         aot_model,\n",
    "        #         sam_gap,\n",
    "        #         max_obj_num,\n",
    "        #         points_per_side,\n",
    "        #         origin_frame,\n",
    "        #     ],\n",
    "        #     outputs=[\n",
    "        #         Seg_Tracker, input_first_frame, click_stack, drawing_board\n",
    "        #     ],\n",
    "        #     queue=False,\n",
    "        #     show_progress=False\n",
    "        # )\n",
    "\n",
    "        # Undo click\n",
    "        click_undo_but.click(\n",
    "            fn = undo_click_stack_and_refine_seg,\n",
    "            inputs=[\n",
    "                Seg_Tracker, origin_frame, click_stack,\n",
    "                aot_model,\n",
    "                long_term_mem,\n",
    "                max_len_long_term,\n",
    "                sam_gap,\n",
    "                max_obj_num,\n",
    "                points_per_side,\n",
    "            ],\n",
    "            outputs=[\n",
    "               Seg_Tracker, input_first_frame, click_stack\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        every_undo_but.click(\n",
    "            fn = undo_click_stack_and_refine_seg,\n",
    "            inputs=[\n",
    "                Seg_Tracker, origin_frame, click_stack,\n",
    "                aot_model,\n",
    "                long_term_mem,\n",
    "                max_len_long_term,\n",
    "                sam_gap,\n",
    "                max_obj_num,\n",
    "                points_per_side,\n",
    "            ],\n",
    "            outputs=[\n",
    "               Seg_Tracker, input_first_frame, click_stack\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        with gr.Tab(label='Video example'):\n",
    "            gr.Examples(\n",
    "                examples=[\n",
    "                    # os.path.join(os.path.dirname(__file__), \"assets\", \"840_iSXIa0hE8Ek.mp4\"),\n",
    "                    os.path.join(os.path.abspath(''), \"assets\", \"blackswan.mp4\"),\n",
    "                    # os.path.join(os.path.dirname(__file__), \"assets\", \"bear.mp4\"),\n",
    "                    # os.path.join(os.path.dirname(__file__), \"assets\", \"camel.mp4\"),\n",
    "                    # os.path.join(os.path.dirname(__file__), \"assets\", \"skate-park.mp4\"),\n",
    "                    # os.path.join(os.path.dirname(__file__), \"assets\", \"swing.mp4\"),\n",
    "                    ],\n",
    "                inputs=[input_video],\n",
    "            )\n",
    "        \n",
    "        with gr.Tab(label='Image-seq expamle'):\n",
    "            gr.Examples(\n",
    "                examples=[\n",
    "                    os.path.join(os.path.abspath(''), \"assets\", \"840_iSXIa0hE8Ek.zip\"),\n",
    "                ],\n",
    "                inputs=[input_img_seq],\n",
    "            )\n",
    "    \n",
    "    app.queue(default_concurrency_limit=1)\n",
    "    app.launch(debug=True, share=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    seg_track_app()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vid-sam",
   "language": "python",
   "name": "vid-sam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
